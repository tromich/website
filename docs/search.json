{
  "articles": [
    {
      "path": "about.html",
      "title": "About me",
      "description": "I am a Geography Ph.D. student at the University of California, Santa Barbara. Currently, I am researching the impacts of climate on conifer needle shedding, using the RHESSys ecohydrological model. I completed my Master's degree in Geography at UC Santa Barbara in 2020, after finishing a study on the impact of solar radiation on decomposition of common California grass species. Prior to attending graduate school, I worked seasonal jobs related to natural resources management for several years, in a variety of ecosystems. I completed my undergraduate degree in Science of Earth Systems at Cornell University in 2013.\n\nIn my free time I enjoy hiking, a passion that dates to childhood and that has inspired me to work in natural resources and conservation. In recent years I have made several trips to Death Valley with my family.\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:48:54-07:00"
    },
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:55:04-07:00"
    },
    {
      "path": "index.html",
      "title": "Trevor Romich",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          website\r\n          \r\n          \r\n          Home\r\n          About Me\r\n          Project Portfolio\r\n          Resume\r\n          Blog\r\n          Death Valley Photos\r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Trevor Romich\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        GitHub\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        Email\r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            I am a Ph.D. student in Geography at the University of California, Santa Barbara, researching the impact of drought on conifer needle shedding, and the relationship this has with climate.\r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Trevor Romich\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              I am a Ph.D. student in Geography at the University of California, Santa Barbara, researching the impact of drought on conifer needle shedding, and the relationship this has with climate.\r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2022-03-13T23:48:55-07:00"
    },
    {
      "path": "photos.html",
      "title": "Death Valley Photos",
      "description": "Photos I've taken from Death Valley. Currently under construction!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:48:55-07:00"
    },
    {
      "path": "Portfolio.html",
      "title": "Project Portfolio",
      "author": [],
      "contents": "\r\n\r\nI have worked with several different programming languages as part of research and coursework. The links below provide several recent examples of my data analysis projects.\r\n\r\n\r\nOxygen Saturation Model Selection\r\n\r\n\r\nNonlinear Models: Lizard Traits Visualization of Fish Ladder Observation Data\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:48:56-07:00"
    },
    {
      "path": "project1.html",
      "title": "Developing a model for oxygen saturation",
      "author": [],
      "contents": "\r\n\r\n\r\nhide\r\n\r\nlibrary(AICcmodavg)\r\nlibrary(dplyr)\r\nlibrary(equatiomatic)\r\nlibrary(knitr)\r\n\r\n\r\n\r\nFor this project, the goal was to test different linear models made using the data available at: https://calcofi.org/ccdata.html\r\nThe models I developed were as follows:\r\nOxygen saturation as a function of water temperature, salinity, and phosphate concentration\r\nOxygen saturation as a function of the three above factors and depth\r\nI will select the better model using AIC, then perform a ten-fold cross-validation on the two models using RMSE (root mean square error).\r\n\r\n\r\nhide\r\n\r\nt2data = read.csv(\"calcofi_seawater_samples.csv\")\r\n\r\n\r\n\r\nFirst, we generate the two models.\r\n\r\n\r\nhide\r\n\r\nmodel1 = lm(o2sat~t_deg_c+salinity+po4u_m,t2data)\r\nmodel2 = lm(o2sat~t_deg_c+salinity+po4u_m+depth_m,t2data)\r\n\r\n\r\n\r\nWe can obtain AIC (Akaiike’s Information Criteria) and corrected AIC values for each model using the functions in AICcmodavg. These values are intended to help select the preferred model.\r\n\r\n\r\nhide\r\n\r\naictable = AIC(model1,model2)\r\naicctable = data.frame(matrix(nrow=1,ncol=2))\r\naicctable[1,1]=AICc(model1)\r\naicctable[1,2]=AICc(model2)\r\ncolnames(aictable)=c(\"Degrees of Freedom\",\"AIC\")\r\nrownames(aictable)=c(\"Model 1\",\"Model 2\")\r\ncolnames(aicctable)=c(\"Model 1\",\"Model 2\")\r\nrownames(aicctable)=\"Corrected AIC\"\r\nkable(aictable)\r\n\r\n\r\n\r\nDegrees of Freedom\r\nAIC\r\nModel 1\r\n5\r\n618.3868\r\nModel 2\r\n6\r\n615.7016\r\n\r\nhide\r\n\r\nkable(aicctable)\r\n\r\n\r\n\r\nModel 1\r\nModel 2\r\nCorrected AIC\r\n619.0251\r\n616.6048\r\n\r\nThe AIC of the 2nd model is lower, and the difference is greater than two points, so it is preferred. This is true both for the regular and corrected AIC.\r\nNext, we perform the tenfold cross-validation.\r\n\r\n\r\nhide\r\n\r\n#rmse function\r\nrmse = function(x,y){\r\n  return(sqrt(mean((x-y)^2)))\r\n}\r\n\r\n\r\n#assign groups to data\r\ni = rep(1:10, length.out=nrow(t2data))\r\nset.seed(10)\r\nt2grdata = t2data %>%\r\n  mutate(group = sample(i, size=n(),replace=FALSE))\r\n\r\n#create output data frame\r\nrmse_output = data.frame(matrix(nrow=0,ncol=2))\r\ncolnames(rmse_output)=c(\"model 1\",\"model 2\")\r\n\r\n#iterate 10 times\r\nfor (i in 1:10){\r\n  train = t2grdata %>%\r\n    filter(group != i)\r\n  test = t2grdata %>%\r\n    filter(group == i)\r\n  \r\n  #generate each model\r\n  testmodel1 = lm(o2sat~t_deg_c+salinity+po4u_m,train)\r\n  testmodel2 = lm(o2sat~t_deg_c+salinity+po4u_m+depth_m,train)\r\n  \r\n  #predict the test data using each model\r\n  predict_model1 = predict(testmodel1,test)\r\n  predict_model2 = predict(testmodel2,test)\r\n  \r\n  #get rmse of each model\r\n  rmse_model1 = rmse(test$o2sat,predict_model1)\r\n  rmse_model2 = rmse(test$o2sat,predict_model2)\r\n  \r\n  #store these\r\n  rmse_output[i,1]=rmse_model1\r\n  rmse_output[i,2]=rmse_model2\r\n}\r\n\r\ntbl1 = rmse_output %>%\r\n  summarize(`Mean Model 1`=mean(rmse_output[,1]),`Mean Model 2` = mean(rmse_output[,2]))\r\n\r\n\r\n\r\nModel 2 has the lower RMSE, although the difference is very small. I would ordinarily be skeptical of overfitting given this, but the AIC value for model 2 is also lower, and AIC includes an attempt to account for overfitting. So I am inclined to favor model 2.\r\n\r\n\r\nhide\r\n\r\nmodel_final = lm(o2sat~t_deg_c+salinity+po4u_m+depth_m,t2data)\r\nsummary(model_final)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = o2sat ~ t_deg_c + salinity + po4u_m + depth_m, data = t2data)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-26.3023  -2.2828  -0.2479   2.1771  19.4459 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) 144.06686   95.36730   1.511   0.1342    \r\nt_deg_c      -0.74981    0.40494  -1.852   0.0672 .  \r\nsalinity     -0.43945    2.98897  -0.147   0.8834    \r\npo4u_m      -37.71159    2.50113 -15.078   <2e-16 ***\r\ndepth_m      -0.03196    0.01497  -2.135   0.0354 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 5.08 on 95 degrees of freedom\r\nMultiple R-squared:  0.9574,    Adjusted R-squared:  0.9557 \r\nF-statistic: 534.3 on 4 and 95 DF,  p-value: < 2.2e-16\r\n\r\nhide\r\n\r\nextract_eq(model_final,use_coefs = TRUE)\r\n\r\n\r\n\\[\r\n\\operatorname{\\widehat{o2sat}} = 144.07 - 0.75(\\operatorname{t\\_deg\\_c}) - 0.44(\\operatorname{salinity}) - 37.71(\\operatorname{po4u\\_m}) - 0.03(\\operatorname{depth\\_m})\r\n\\]\r\n\r\nAbove is the equation for Model 2, our preferred model which includes all four variables.\r\nInterestingly, salinity (which I didn’t exclude from either model the first time around) is not shown as having even a marginally significant impact on the prediction. So let’s try another model that excludes salinity.\r\n\r\n\r\nhide\r\n\r\n#here we are simply redoing the steps we did for model 1 and 2\r\n\r\n#generate the model\r\nmodel3 = lm(o2sat~t_deg_c+po4u_m+depth_m,t2data)\r\nsummary(model3)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = o2sat ~ t_deg_c + po4u_m + depth_m, data = t2data)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-26.326  -2.363  -0.237   2.232  19.284 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) 130.07069    5.65888  22.985   <2e-16 ***\r\nt_deg_c      -0.78428    0.32847  -2.388   0.0189 *  \r\npo4u_m      -37.96412    1.80878 -20.989   <2e-16 ***\r\ndepth_m      -0.03254    0.01436  -2.266   0.0257 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 5.054 on 96 degrees of freedom\r\nMultiple R-squared:  0.9574,    Adjusted R-squared:  0.9561 \r\nF-statistic: 719.8 on 3 and 96 DF,  p-value: < 2.2e-16\r\n\r\nhide\r\n\r\naictable = AIC(model1,model2,model3)\r\naicctable = data.frame(matrix(nrow=1,ncol=3))\r\naicctable[1,1]=AICc(model1)\r\naicctable[1,2]=AICc(model2)\r\naicctable[1,3]=AICc(model3)\r\ncolnames(aictable)=c(\"Degrees of Freedom\",\"AIC\")\r\nrownames(aictable)=c(\"Model 1\",\"Model 2\",\"Model 3\")\r\ncolnames(aicctable)=c(\"Model 1\",\"Model 2\",\"Model 3\")\r\nrownames(aicctable)=\"Corrected AIC\"\r\nkable(aictable)\r\n\r\n\r\n\r\nDegrees of Freedom\r\nAIC\r\nModel 1\r\n5\r\n618.3868\r\nModel 2\r\n6\r\n615.7016\r\nModel 3\r\n5\r\n613.7244\r\n\r\nhide\r\n\r\nkable(aicctable)\r\n\r\n\r\n\r\nModel 1\r\nModel 2\r\nModel 3\r\nCorrected AIC\r\n619.0251\r\n616.6048\r\n614.3627\r\n\r\nModel 3 does indeed have a lower AIC and corrected AIC than Model 2. The difference is just barely less than two points for AIC, but greater than two points for corrected AIC.\r\n\r\n\r\nhide\r\n\r\n#assign groups to data\r\ni = rep(1:10, length.out=nrow(t2data))\r\nset.seed(10)\r\nt2grdata = t2data %>%\r\n  mutate(group = sample(i, size=n(),replace=FALSE))\r\n\r\n#create output data frame\r\nrmse_output = data.frame(matrix(nrow=0,ncol=2))\r\ncolnames(rmse_output)=c(\"model 1\",\"model 2\")\r\n\r\n#iterate 10 times\r\nfor (i in 1:10){\r\n  train = t2grdata %>%\r\n    filter(group != i)\r\n  test = t2grdata %>%\r\n    filter(group == i)\r\n  \r\n  #generate each model\r\n  testmodel1 = lm(o2sat~t_deg_c+salinity+po4u_m,train)\r\n  testmodel2 = lm(o2sat~t_deg_c+salinity+po4u_m+depth_m,train)\r\n  testmodel3 = lm(o2sat~t_deg_c+po4u_m+depth_m,train)\r\n  \r\n  #predict the test data using each model\r\n  predict_model1 = predict(testmodel1,test)\r\n  predict_model2 = predict(testmodel2,test)\r\n  predict_model3 = predict(testmodel3,test)\r\n  \r\n  #get rmse of each model\r\n  rmse_model1 = rmse(test$o2sat,predict_model1)\r\n  rmse_model2 = rmse(test$o2sat,predict_model2)\r\n  rmse_model3 = rmse(test$o2sat,predict_model3)\r\n  \r\n  #store these\r\n  rmse_output[i,1]=rmse_model1\r\n  rmse_output[i,2]=rmse_model2\r\n  rmse_output[i,3]=rmse_model3\r\n}\r\n\r\ntbl2 = rmse_output %>%\r\n  summarize(`Mean Model 1`=mean(rmse_output[,1]),`Mean Model 2` = mean(rmse_output[,2]),`Mean Model 3` = mean(rmse_output[,3]))\r\nkable(tbl2)\r\n\r\n\r\nMean Model 1\r\nMean Model 2\r\nMean Model 3\r\n4.741503\r\n4.660267\r\n4.608762\r\n\r\nModel 3 has the lowest RMSE, but the difference is even less than the difference between Model 1 and Model 2.\r\nLet’s review all the information we have:\r\nModel 2 includes a term, salinity, which does not have even close to a marginally significant (i.e. at 90% confidence) impact on the predicted values in the model.\r\nModel 3 has a lower AIC than Model 2, which excludes salinity. However the difference between the models is less than 2 points, so we cannot conclude that Model 3 is superior to Model 2 based on this.\r\nModel 3 has a lower corrected AIC than Model 2, and by over two points. However, corrected AIC is intended to address problems with data where the sample size is very small, smaller than our available data.\r\nModel 3 has a lower RMSE than Model 2, but by an extremely small amount.\r\nOverall, Models 2 and 3 seem very close in performance, with mixed results suggesting that Model 3 may be the preferred model. In this scenario, I think the best option is to prefer the model that includes fewer terms - Model 3 - especially considering that the extra term in Model 2 does not appear to have a significant impact on Model 2’s predictions.\r\nTherefore, our new finalized model becomes:\r\n\r\n\r\nhide\r\n\r\nmodel_final = lm(o2sat~t_deg_c+po4u_m+depth_m,t2data)\r\nsummary(model_final)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = o2sat ~ t_deg_c + po4u_m + depth_m, data = t2data)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-26.326  -2.363  -0.237   2.232  19.284 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) 130.07069    5.65888  22.985   <2e-16 ***\r\nt_deg_c      -0.78428    0.32847  -2.388   0.0189 *  \r\npo4u_m      -37.96412    1.80878 -20.989   <2e-16 ***\r\ndepth_m      -0.03254    0.01436  -2.266   0.0257 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 5.054 on 96 degrees of freedom\r\nMultiple R-squared:  0.9574,    Adjusted R-squared:  0.9561 \r\nF-statistic: 719.8 on 3 and 96 DF,  p-value: < 2.2e-16\r\n\r\nhide\r\n\r\nextract_eq(model_final,use_coefs = TRUE)\r\n\r\n\r\n\\[\r\n\\operatorname{\\widehat{o2sat}} = 130.07 - 0.78(\\operatorname{t\\_deg\\_c}) - 37.96(\\operatorname{po4u\\_m}) - 0.03(\\operatorname{depth\\_m})\r\n\\]\r\n\r\nAll of the terms in this model are significant to at least 95% confidence.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:49:05-07:00"
    },
    {
      "path": "project3.html",
      "title": "Nonlinear modeling of lizard physiological data",
      "author": [],
      "contents": "\r\n\r\n\r\nhide\r\n\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\nlibrary(patchwork)\r\nlibrary(knitr)\r\nlibrary(broom)\r\n\r\n\r\n\r\nObjective:\r\nUsing the data from Lightfoot, D. and W.G. Whitford. 2020. Lizard pitfall trap data from 11 NPP study locations at the Jornada Basin LTER site, 1989-2006 ver 37. Environmental Data Initiative. https://doi.org/10.6073/pasta/4a6e258fb49c31e222ecbbcfd128967f\r\nData is measurement of weight and snout to vent length for various lizard species, divided by sex.\r\nWe will fit a model of weight as a function of snout to vent length of the form w = a*svl^b\r\n\r\n\r\nhide\r\n\r\nt2data = read.csv(\"lizard.csv\")\r\n\r\n\r\n\r\nFirst, let’s visualize the data by plotting weight against snouht to vent length, since we ultimately will be creating a function that does that.\r\n\r\n\r\nhide\r\n\r\nplot1 = ggplot(data=t2data,mapping=aes(x=SV_length,y=weight))+geom_point()+theme_classic()+labs(x=\"Snout to vent length (mm)\",y=\"Weight (g)\")\r\n#don't adjust axis, easier to see what's going on at weights near zero if they are away from x axis\r\nplot1+plot_annotation(caption=\"Weight in grams vs snout-vent length in mm, for all sampled lizards.\\nData from Lightfoot, D. and W.G. Whitford. 2020. Lizard pitfall trap data from 11\\nNPP study locations at the Jornada Basin LTER site, 1989-2006 ver 37.\\nEnvironmental Data Initiative. \\nhttps://doi.org/10.6073/pasta/4a6e258fb49c31e222ecbbcfd128967f\")\r\n\r\n\r\n\r\n\r\nThe curve to the data is not super sharp, as a rough initial guess I would expect b to be between 1 and 2.\r\nBut let’s get better estimates for the parameters!\r\nFirst we log transform the data, and then fit a linear regression to the result.\r\n\r\n\r\nhide\r\n\r\n#log transform the data and add as new columns\r\nt2data = mutate(t2data,log_wt = log(weight,base=10))\r\nt2data = mutate(t2data,log_svl = log(SV_length,base=10))\r\n\r\n#fit linear regression for log data\r\nml= lm(log_wt~log_svl,data=t2data)\r\nsummary(ml)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = log_wt ~ log_svl, data = t2data)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-1.50177 -0.08274  0.01366  0.09089  2.50953 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) -3.68084    0.05051  -72.88   <2e-16 ***\r\nlog_svl      2.53712    0.03033   83.66   <2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 0.162 on 1984 degrees of freedom\r\nMultiple R-squared:  0.7792,    Adjusted R-squared:  0.779 \r\nF-statistic:  7000 on 1 and 1984 DF,  p-value: < 2.2e-16\r\n\r\nWe will use the coefficients from this linear model as initial estimates for coefficients a and b, and then use those starting estimates to generate our nonlinear model using the nls function.\r\n\r\n\r\nhide\r\n\r\n#set up our equation\r\neqn = function(svl,a,b){\r\n  w=a*svl^b\r\n  return(w)\r\n}\r\n\r\n#generate the model using estimates from the linear model on the log\r\nnls1 = nls(weight~eqn(SV_length,a,b),data=t2data,start=list(a=(10^ml$coefficients[1]),b=ml$coefficients[2]),trace=FALSE)\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\n#get an additional column of the fitted model predictons\r\nt2data = augment(nls1,data=t2data)\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\nnls1tidy = broom::tidy(nls1)\r\nkable(nls1tidy,caption=c(\"Summary of model terms\"))\r\n\r\n\r\nTable 1: Summary of model terms\r\nterm\r\nestimate\r\nstd.error\r\nstatistic\r\np.value\r\na\r\n0.0003411\r\n0.0000400\r\n8.538421\r\n0\r\nb\r\n2.4532066\r\n0.0269791\r\n90.930009\r\n0\r\n\r\nRemember that the model’s format is weight = a*svl^b.\r\nIn reality, b is slightly higher than 2, and this is compensated by the extremely low a value.\r\n\r\n\r\nhide\r\n\r\n#plot the fitted weight against the actual weight\r\nplot2 = ggplot(data = t2data,mapping=aes(x=SV_length,y=weight))+geom_point(aes(color=sex))+labs(y=\"Weight (g)\", x = \"Snout to vent length (mm)\")+geom_line(data=t2data,mapping=aes(x=SV_length,y=.fitted))+theme_classic()\r\nplot2+plot_annotation(caption=\"Observed and predicted weight as a function of lizard snout to vent length.\\nBlack line represents the model predictions while points represent observed data.\")\r\n\r\n\r\n\r\n\r\nThis model does a pretty good job of reproducing observations. But can we do better?\r\nNext, we will make a model using a subset of the data, for Cnemidophorus tigrisatus males only. First we filter for only our desired sex and species. After that the steps are similar to what we did before. We will also want to compare the models, so we calculate the root mean square error for each model as well.\r\n\r\n\r\nhide\r\n\r\nt2data2 = filter(t2data,sex==\"M\"&spp==\"CNTI\")\r\ncolnames(t2data2)=c(\"x\",\"spp\",\"sex\",\"SV_length\",\"weight\",\"log_wt\",\"log_svl\",\"Fitted General\",\"Residuals General\")\r\n\r\nml2= lm(log_wt~log_svl,data=t2data2)\r\n\r\n\r\n#generate the model using estimates from the linear model on the log\r\nnls2 = nls(weight~eqn(SV_length,a,b),data=t2data2,start=list(a=(10^ml2$coefficients[1]),b=ml2$coefficients[2]),trace=FALSE)\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\n#get an additional column of the fitted model predictons\r\nt2data2 = augment(nls2,data=t2data2)\r\ncolnames(t2data2)=c(\"x\",\"spp\",\"sex\",\"SV_length\",\"weight\",\"log_wt\",\"log_svl\",\"Fitted General\",\"Residuals General\",\"Fitted Specific\",\"Residuals Specific\")\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\n#rmse function\r\nrmse = function(x,y){\r\n  return(sqrt(mean((x-y)^2)))\r\n}\r\nrmse_model1 = rmse(t2data2$weight,t2data2$`Fitted General`)\r\nrmse_model2 = rmse(t2data2$weight,t2data2$`Fitted Specific`)\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\n#plot the fitted weight against the actual weight\r\nplot3 = ggplot(data = t2data2,mapping=aes(x=SV_length,y=`Fitted General`))+geom_line(aes(color=\"Fitted General\"))+geom_line(aes(color=\"Fitted Specific\",x=SV_length,y=`Fitted Specific`))+geom_point(aes(color=\"Observed\",x=SV_length,y=weight))+labs(y=\"Model predicted weight (g)\", x = \"Snout to vent length (mm)\")+theme_classic()\r\nplot3+plot_annotation(caption=\"Observed and predicted weights using both the general and sex/species specific models\\nRMSE for Fitted General: 3.56\\nRMSE for Fitted Specific: 3.35\\nThe preferred model for this data is the species/sex specific model, as it has lower RMSE.\\nHowever, this model was developed specific for male Cnemidophorus tigrisatus,\\nand may not perform as well as the general model for females or other species.\")\r\n\r\n\r\n\r\n\r\nThis model outperforms our general model for this subset of the data. We wouldn’t necessarily expect it to do better for a different species or sex, though. One could easily automate the generation of additional models for specific combinations of species and sex by iterating the process above over each combination of sex and species.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:49:09-07:00"
    },
    {
      "path": "project4.html",
      "title": "Fish Passage on the Willamette River, Oregon",
      "author": [],
      "contents": "\r\n\r\nIntroduction\r\n\r\n Image source: M.O. Stevens & Fcb981 (ed.). 2007. Accessed 03/13/2022 via Wikipedia. The image is in the public domain.\r\nThe Willamette River is located in western Oregon and flows through the city of Portland. Fish counts have been collected at the Sullivan project dam, located at Willamette Falls, for fish making use of ladder to bypass the dam. We will be looking at three species of interest: Coho, Jack Coho, and Steelhead.\r\nData (c) 2001-2022, Oregon Department of Fish & Wildlife. Willamette Falls (Sullivan Project) Adult Passage Visual Counts. Accessed 03/13/2022 via Google Drive.\r\nAdditional data can be downloaded via Columbia River DART; the organization providing the data varies depending on the selected location.\r\nThe dam and fish ladder are located near West Lynn, Oregon, south of Portland.\r\n\r\nImage (c) 2022 Google and TerraMetrics, accessed 03/13/2022 at  Google Maps.\r\n\r\n\r\nhide\r\n\r\nfishes = read.csv(\"willamette_fish_passage.csv\") #load the data\r\n\r\n#we are working with Coho, Jack.Coho, and Steelhead, so let's get rid of everything else\r\n#we can remove the NAs (replacing with 0) at the same time\r\n\r\nfishes2 = data.frame(replace_na(pull(fishes,Date),0),replace_na(pull(fishes,Coho),0), #it doesn't appear as though there are NAs in the date column, but for consistency's sake...\r\n                     replace_na(pull(fishes,Jack.Coho),0),replace_na(pull(fishes,Steelhead),0))\r\ncolnames(fishes2)=c(\"Date\",\"Coho\",\"Jack Coho\",\"Steelhead\")\r\n\r\nfishes2$Date = mdy(fishes2$Date)\r\nfishes = as_tsibble(fishes2,key=NULL,index=Date)\r\n\r\n\r\n\r\nData Visualization and Takeaways\r\nOver Time\r\nHere we present the time series data for each of the three species of interest.\r\n\r\n\r\nhide\r\n\r\n#plot Coho, Jack.Coho, and Steelhead\r\n\r\n#get the species as a column value\r\nfishes_plotting = melt(as.data.frame(fishes),id=1)\r\ncolnames(fishes_plotting)=c(\"Date\",\"Species\",\"Count\")\r\n\r\n\r\n\r\nfishplot1 = ggplot(fishes_plotting,aes(x=Date,y=Count,group=Species))+geom_point(aes(color=Species,shape=Species),size=1)+#need to make the 3 lines a bit bigger so they can be seen where they overlap\r\n  theme_minimal()+scale_shape_manual(values=c(0,4,3))\r\n  \r\n\r\nfishplot1+plot_annotation(caption=\"Figure 1: Count over time for Coho, Jack Coho, and Steelhead, from 2001 to 2010.\\nSpecies are differentiated using the same color and symbol as in other figures.\\nHowever, the size of each point has been made smaller in this figure to reduce clutter.\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nhide\r\n\r\nfishplot2=ggplot(fishes,aes(x=Date,y=Coho))+geom_point(aes(color=\"#F8766D\",shape=0))+theme_minimal()+\r\n  theme(legend.position=\"none\")+scale_shape_identity()+scale_color_identity()\r\nfishplot3=ggplot(fishes,aes(x=Date,y=`Jack Coho`))+geom_point(aes(color=\"#00BA38\",shape=4))+theme_minimal()+\r\n  theme(legend.position=\"none\")+scale_shape_identity()+scale_color_identity()\r\nfishplot4=ggplot(fishes,aes(x=Date,y=Steelhead))+geom_point(aes(color=\"#619CFF\",shape=3))+theme_minimal()+\r\n  theme(legend.position=\"none\")+scale_shape_identity()+scale_color_identity()\r\n\r\n(fishplot2/fishplot3/fishplot4) + plot_annotation(caption=\"Figure 2: Separate graphs of count over time for each of Coho, Jack Coho, and Steelhead, from 2001 to 2010.\\nSpecies are differentiated using the same color and symbol as in other figures.\\nHowever, the size of each point has been made smaller in this figure to reduce clutter.\")\r\n\r\n\r\n\r\n\r\nFish counts rise and fall in a cyclical pattern for all three species. The timing of peak fish counts is approximately the same for Coho and Jack Coho, and happens in the latter half of the year. Outside the relatively short peak observation time, Coho and Jack Coho are virtually absent from the fish ladder. Steelhead count pattern differs slightly; it peaks at approximately the middle of the year, and there is a much wider range around the peak where steelhead are still being observed, albeit at lower numbers.\r\nSeasonplots\r\nBy using a season plot we can more easily observe the variation in fish counts over the course of a year.\r\n\r\n\r\nhide\r\n\r\n#create 3 plots, 1 for each species\r\ncoho_se=gg_season(fishes,y=Coho)+theme_minimal()+theme(legend.position=\"none\")\r\njcoho_se = gg_season(fishes,y=`Jack Coho`)+theme_minimal()+theme(legend.position=\"none\")\r\nsth_se = gg_season(fishes,y=Steelhead)+theme_minimal()+theme(legend.position=\"bottom\") #we only need 1 legend since the colors for each year are the same on all 3 plots\r\n\r\n#plot them\r\ncoho_se/jcoho_se/sth_se+plot_annotation(caption=\"Figure 3: Season plots for the three species.\\nY axis indicates the number of individuals observed, and the color of the lines on each plot indicates the year.\")\r\n\r\n\r\n\r\n\r\nThe season plot bears out the conclusions from looking at the time series data across all years. Coho and Jack Coho peak in October (late in the year) and are more ore less absent outside the August-December range. Conversely, Steelhead are observed throughout the year, with the peak observation time being in May-June. The season plot makes it easier to see that, for Steelhead, August-December counts are much lower than the counts for January-July.\r\nAnnual Totals\r\nHere we consider the yearly total counts at the fish ladder for each species.\r\n\r\n\r\nhide\r\n\r\n#get just the year in a column\r\nfishes_yr = as_tibble(fishes) %>%\r\n  mutate(Date=year(Date))%>%\r\n  group_by(Date) %>%\r\n  summarise(Coho = sum(Coho),`Jack Coho` = sum(`Jack Coho`),Steelhead = sum(Steelhead))\r\ncolnames(fishes_yr)=c(\"Year\",\"Coho\",\"Jack Coho\",\"Steelhead\")\r\nfishes_yr$Year=as.character(fishes_yr$Year) #converting it to a character data type should force it to be treated as categorical by default\r\n\r\nfy2 = melt(as.data.frame(fishes_yr),id=1)\r\ncolnames(fy2)=c(\"Year\",\"Species\",\"Count\")\r\n\r\nfyplot = ggplot(fy2,aes(x=Year,y=Count,group=Species))+geom_point(aes(color=Species,shape=Species),size=1.5,stroke=2)+\r\n  theme_minimal()+scale_shape_manual(values=c(0,4,3))+labs(y=\"Total Annual Count\")\r\nfyplot+plot_annotation(caption=\"Figure 4: Total annual count by year, for each of the three species of interest.\\nSpecies are differentiated using the same color and symbol as in other figures.\")\r\n\r\n\r\n\r\n\r\nBecause Jack Coho counts are much lower than the other species, a separate graph makes it easier to see the pattern in annual counts for Jack Coho.\r\n\r\n\r\nhide\r\n\r\nfyplot2 = ggplot(fishes_yr,aes(x=Year,y=`Jack Coho`))+geom_point(aes(color=\"#00BA38\",shape=4,size=1.5,stroke=2))+\r\n  theme_minimal()+labs(y=\"Jack Coho Count\")+theme(legend.position=\"none\")+scale_shape_identity()+scale_color_identity()+scale_size_identity()\r\nfyplot2+plot_annotation(caption=\"Figure 5: Total annual count by year for Jack Coho.\\nSpecies are differentiated using the same color and symbol as in other figures.\")\r\n\r\n\r\n\r\n\r\nFrom these figures, we observe:\r\nSteelhead annual counts are high (25000-50000) early in the 2000s, but decline to 20000-30000 from 2005 to 2009. The 2010 count for Steelhead is higher, at almost 35000; this may indicate that the population using the fish ladder is increasing again, but it is probably too soon to tell.\r\nCoho annual counts for most of the 2000s are relatively low compared to Coho counts in 2009 and 2010; values jump from a range of about 2000-10000 to over 20000 in the last two years of the dataset.\r\nJack Coho annual counts range from as low as 100 to about 3000, and this range does not seem to show an obvious increasing trend over the dataset.\r\nFor all three species, annual counts seem to rise and fall in an approximately 2-4 year cycle.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-13T23:49:17-07:00"
    },
    {
      "path": "Resume.html",
      "title": "My resume",
      "author": [],
      "contents": "\r\n\r\n\r\n.a { display : flex }\r\n\r\n\r\n\r\n\r\nIf the viewer below is not working, click\r\n\r\n this link \r\n\r\nto download a copy of my current resume\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-14T00:19:22-07:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
